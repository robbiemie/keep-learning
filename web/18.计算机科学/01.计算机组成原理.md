# 计算机组成原理

> 计算机组成原理是计算机科学与工程中的一个重要领域，主要涉及计算机硬件和底层体系结构的原理、设计和实现。

## 冯诺依曼体系结构

> 冯·诺依曼体系结构，又称为冯·诺依曼架构，是计算机体系结构的一种基本设计思想，由物理学家约翰·冯·诺伊曼（John von Neumann）在1945年提出。冯·诺依曼体系结构在计算机科学历史上起到了里程碑的作用，成为现代计算机设计的基石。

冯·诺依曼体系结构的主要特点包括：

1. 存储程序： 冯·诺依曼体系结构将程序和数据存储在同一存储器中，这称为存储程序概念。程序被视为一系列二进制指令，存储在内存中，计算机可以按照程序存储器中的地址顺序执行这些指令。
2. 二进制系统： 冯·诺依曼体系结构使用二进制来表示指令和数据，所有的操作都以二进制形式进行。
3. 存储器： 存储器被划分为两个部分，一部分用于存储指令（程序存储器），另一部分用于存储数据。这两个存储器可以独立访问。
4. 指令执行顺序： 冯·诺依曼计算机按照顺序执行存储在程序存储器中的指令，每条指令执行后，计算机自动转移到下一条指令。
5. 单一总线结构： 冯·诺依曼体系结构使用单一总线来连接中央处理器（CPU）、存储器和输入/输出设备，通过总线进行数据和控制信号的传输。
6. 中央处理单元（CPU）： CPU 包括算术逻辑单元（ALU）和控制单元（CU），负责执行指令和控制计算机的操作。
7. 按需取数和存储： 按照需要从存储器中取指令和数据，并在需要时将结果存储回存储器。


## 相关概念

- 带宽
  - 定义: 数据传输通道的最大数据传输速率，通常以每秒传输的比特数（bps，比特每秒）或字节数（Bps，字节每秒）表示
  - 用途： 带宽用于描述通信通道的能力，即通道在单位时间内能够传输多少数据。
- 容量
  - 定义: 存储设备或存储介质可以容纳的数据量，通常以字节数、千字节（KB）、兆字节（MB）、吉字节（GB）等表示
  - 用途： 容量用于描述存储设备的大小，即设备可以存储多少数据。在硬盘驱动器、内存模块、存储卡等设备中，容量表示可用于存储的总数据量。
- 吞吐量
  - 定义: 在单位时间内完成的指令数
- 经典 CPU 性能公式: cpu 时间 = 指令数 ✖️ CPI(每条指令所需时间周期数) ✖️ 时钟周期时间


## 组成结构

1. 中央控制单元(CPU)
  - 控制单元 (Control Unit): 负责指令的解码和执行，协调计算机的各个部件。
  - 算术逻辑单元 (Arithmetic Logic Unit, ALU): 执行算术和逻辑运算。
2. 存储器(Memory)
  - 主存储器 (Main Memory/RAM): 用于存储程序和数据，是CPU能够直接访问的存储区域。
  - 辅助存储器 (Secondary Storage): 例如硬盘、固态硬盘 (SSD) 等，用于永久存储数据。
3. 输入/输出系统(I/O System)
  - 输入设备: 用于接受用户输入的设备，如键盘、鼠标。
  - 输出设备: 用于向用户显示结果的设备，如显示器、打印机。
  - I/O控制器: 管理计算机与外部设备之间的数据传输。
  - I/O端口 (I/O Port): 用于连接计算机与外部设备的接口。
4. 总线系统(Bus System)
  - 地址总线 (Address Bus): 传递CPU到主存储器的地址信息。
  - 数据总线 (Data Bus): 传递CPU和主存储器之间的数据。
  - 控制总线 (Control Bus): 传递控制信号，如读/写、时钟等。
5. 存储器层次结构
  - 高速缓存 (Cache): 位于CPU和主存储器之间，用于加速数据访问。
  - 寄存器 (Register): 位于CPU内部，速度最快，用于存储临时数据和指令。
6. 指令集架构(ISA)
  - RISC (Reduced Instruction Set Computing): 指令集较小，每条指令执行时间短。
  - CISC (Complex Instruction Set Computing): 指令集较大，每条指令执行时间可能较长。
7. 系统总体结构
  - 单处理器系统: 包括一个CPU，用于执行单个任务。
  - 多处理器系统: 包括多个CPU，可同时执行多个任务。
8. 时钟系统(Clock System)
  - 时钟 (Clock): 提供计时信号，同步各个部件的操作。


## CPU

> 中央处理器（Central Processing Unit, CPU）是计算机系统中的核心组件，它承担着执行程序和处理数据的关键任务。CPU 的主要作用包括：

1. 指令解码和执行： CPU 从主存储器中读取指令，然后对这些指令进行解码，确定执行哪些操作。接着，它执行这些操作，这可能涉及算术运算、逻辑运算、数据传输等。

2. 运算能力： CPU 包含算术逻辑单元（Arithmetic Logic Unit, ALU），负责执行各种算术运算（加法、减法、乘法、除法等）和逻辑运算（与、或、非等）。

3. 控制计算机的操作： 控制单元（Control Unit）是 CPU 的一部分，负责协调和控制计算机的各个部件。它确保指令按照正确的顺序执行，并管理数据的流动。

4. 寄存器存储： CPU 包含多个寄存器，这些寄存器用于暂时存储指令和数据。寄存器速度非常快，是 CPU 内部进行数据处理的重要存储区域。

5. 高速缓存管理： CPU 通过高速缓存（Cache）提高对内存的访问速度。高速缓存存储了最常用的指令和数据，以提供更快的存取速度。

6. 中断处理： CPU 能够响应各种事件，如外部设备的输入、时钟中断等。当发生中断时，CPU 暂停当前任务，跳转到中断处理程序执行相应的操作。

7. 时序控制： CPU 中包含时钟（Clock），时钟发出的脉冲信号用于同步整个计算机系统的操作。时钟的频率决定了 CPU 的工作速度。

8. 支持指令集架构： CPU 实现了特定的指令集架构（Instruction Set Architecture, ISA），包括执行特定的指令集和提供相应的寻址方式。

## 多核CPU

> CPU多核指的是一颗处理器芯片上集成了多个处理核心（CPU核心）。相比于单核处理器，多核处理器具有多个独立的处理单元，每个核心能够同时执行不同的指令序列。

多核处理器的引入带来了一系列的优势和应用：
1. 并行处理： 多核处理器允许多个核心同时执行任务，实现并行处理。这对于那些可以被分解为独立子任务的应用程序来说尤为重要，如科学计算、图形渲染、多媒体处理等。
2. 提高性能： 多核处理器可以在相同的时间内执行更多的指令，从而提高整体性能。虽然单个核心的时钟频率可能不如单核处理器高，但多个核心的并行执行能力弥补了这一差距。
3. 资源隔离： 多核处理器允许操作系统将不同的任务分配到不同的核心上运行，实现资源的有效隔离。这有助于提高系统的稳定性和可靠性。
4. 能效优势： 在相同性能水平下，多核处理器通常比单核处理器更能有效地利用电能。这是因为多核处理器在单位时间内可以完成更多的工作，从而降低了每个核心的工作负载。
5. 多线程支持： 多核处理器对多线程应用程序更为友好。每个核心都能独立执行一个线程，从而提高多线程应用程序的整体性能。
6. 适应并发任务： 随着计算机应用的复杂性增加，许多任务需要并发处理。多核处理器能够更好地适应这种需求，加速处理大规模并行任务的能力。
7. 提高系统响应速度： 在多核系统中，一个核心执行繁重的计算任务不会影响其他核心执行其他任务，因此系统更能保持响应速度。



## 指令集

> 指令集是一组计算机处理器能够理解和执行的机器指令的集合。每个指令都对应处理器硬件上的一个操作，例如算术运算、逻辑运算、数据传输等。指令集架构定义了计算机体系结构的底层操作。

指令集通常分为两类：

1. RISC（精简指令集计算机）指令集： RISC架构采用简化的指令集，每个指令的执行时间相对较短，处理器的时钟周期相对较快。这样设计的目的是提高指令的执行效率和降低硬件成本。

2. CISC（复杂指令集计算机）指令集： CISC架构包含更多复杂的指令，一条指令可能执行多个操作，但每个指令的执行时间相对较长。CISC的设计目的是提供更高层次的抽象，减少程序员的负担，但也导致了更复杂的硬件结构。

### 1. ARM指令集（RISC）：

- MOV (Move): 数据传送指令，将数据从一个寄存器复制到另一个寄存器。

```assembly
MOV R0, R1   ; 将R1寄存器的值传送到R0寄存器
```

- ADD (Addition): 加法指令，将两个寄存器中的值相加。

```assembly
ADD R0, R1, R2   ; 将R1和R2寄存器中的值相加，结果存储在R0中
```

- B (Branch): 跳转指令，无条件跳转到指定地址。

```assembly
B Label    ; 无条件跳转到标签Label处
```

### 2. x86指令集（CISC）：

- MOV (Move): 数据传送指令，将数据从一个位置复制到另一个位置。

```assembly
MOV AX, BX   ; 将BX的值传送到AX寄存器
```

- ADD (Addition): 加法指令，将两个操作数相加。

```assembly
ADD AX, BX   ; 将AX寄存器和BX寄存器中的值相加，结果存储在AX中
```

- JMP (Jump): 跳转指令，无条件跳转到指定地址。

```assembly
JMP Label    ; 无条件跳转到标签Label处
```



## 总线系统

> 总线系统是计算机内部各个组件之间进行数据传输的通信系统。总线是一组用于传输信息的电子线路，将计算机内部的各个部件连接起来，使它们能够协同工作。

总线系统包括以下几个主要方面：

1. 地址总线（Address Bus）： 地址总线是用于传输地址信息的电子线路。它决定了CPU对内存和外设的寻址范围，即计算机可以寻址的内存和外设地址的总数。例如，一个32位地址总线可以寻址$2^{32}$个不同的地址。

2. 数据总线（Data Bus）： 数据总线是用于传输数据的电子线路。它传输CPU和内存、I/O设备之间的二进制数据。数据总线的宽度（比特数）决定了一次可以传输的数据量，例如，一个32位数据总线可以同时传输32位（4字节）的数据。

3. 控制总线（Control Bus）： 控制总线是用于传输控制信号的电子线路。它传输指令、时钟、读/写信号等控制信息，用于协调和控制各个部件的操作。控制总线也包括一些特定的信号，如中断请求、总线请求等。

总线系统的工作过程如下：

- 写操作： 当CPU要向内存或外设写入数据时，CPU将地址信息放入地址总线，将数据放入数据总线，并通过控制总线发送写入信号。接收到这些信号的内存或外设将相应的数据写入指定地址。

- 读操作： 当CPU需要从内存或外设读取数据时，CPU将地址信息放入地址总线，并通过控制总线发送读取信号。内存或外设将相应地址处的数据放入数据总线，CPU读取这些数据。

- 控制信号： 控制总线负责传输各种控制信号，例如时钟信号用于同步各个部件的操作，读/写信号表示当前是读取还是写入操作，中断请求信号用于通知CPU有中断事件等。

总线系统的性能和效率对整个计算机系统的运行速度有重要影响。总线宽度的增加可以提高一次性传输的数据量，从而加快数据传输速度。总线的设计也会受到计算机体系结构中内存层次结构的影响，因为不同层次的存储设备可能需要不同速度和宽度的总线。


## 时钟系统

> 时钟系统在计算机中起着关键的作用，它提供了一个基准时序，用于同步和协调计算机系统中各个部件的工作。时钟系统包括时钟源、时钟信号和时钟频率等组成部分。

以下是时钟系统的主要概念和作用：


1. 时钟源（Clock Source）： 时钟源是时钟系统的根源，它提供了计时脉冲。在现代计算机中，通常使用晶体振荡器作为时钟源。晶体振荡器是一种高稳定性的电子元件，它可以产生固定频率的振荡信号，作为计算机的主时钟。

2. 时钟信号（Clock Signal）： 时钟信号是由时钟源发出的脉冲信号，它以固定的频率周期性地变化。时钟信号的变化用于同步和触发计算机内部各个组件的操作。

3. 时钟频率（Clock Frequency）： 时钟频率表示时钟信号每秒的脉冲次数，通常以赫兹（Hz）为单位。时钟频率越高，计算机内部的操作速度越快。时钟频率直接影响到计算机的性能，因此提高时钟频率是提升计算机性能的一种方法。

4. 时钟周期（Clock Cycle）： 时钟周期是指时钟信号的一个完整周期，即从一个上升沿到下一个上升沿的时间。时钟周期的倒数就是时钟频率，因为频率是周期的倒数。

5. 时钟同步： 时钟信号的同步性质确保了计算机内部各个部件在相同的时刻执行相应的操作。通过时钟同步，计算机可以按照协调的时序执行指令和传输数据。

6. 时钟分频（Clock Divider）： 有时候，为了适应不同部件的工作速度，计算机会使用时钟分频器将主时钟信号分频，以产生不同频率的时钟信号，以供不同部件使用。

7. 时钟周期的计算： 时钟周期的计算方式为时钟周期（秒） = 1 / 时钟频率（赫兹）。


## GPU

- 与 cpu 的通信: 通过共享内存(一般为主内存)进行通信
- 大模型训练为什么使用 GPU 和不是 CPU
  - 并行计算: GPU 相比 CPU 拥有更多核心. 消费级 gpu 拥有几千个核心, 高端 gpu 拥有几万个核心, 而 cpu 一般只有两位数的核心
  - 高带宽内存: GPU 拥有高带宽图形内存, 而 CPU 只有微小的高速缓存. 因此 gpu 可以进行大量数据的读写

## 计算机寻址

> 计算机寻址是指确定存储器中某个位置的过程。计算机通过使用地址来唯一标识存储器中的每个单元。地址是一个数字，它表示存储器中的特定位置。

计算机寻址的方式取决于体系结构和寻址模式，以下是一些常见的寻址方式：

1. 直接寻址（Direct Addressing）： 最简单的寻址方式，指令中包含了要访问的存储器地址。例如，LOAD 1000 表示从地址为1000的存储单元加载数据。
2. 间接寻址（Indirect Addressing）： 指令中包含一个地址，该地址指向存储器中的另一个地址，从而获取数据。这允许间接引用存储器位置。
3. 基址寻址（Base Addressing）： 使用基址寄存器中的值与指令中的偏移量相加，以计算实际的存储器地址。这允许程序在一个基本地址上定义数据结构，然后通过偏移量来访问不同的元素。
4. 相对寻址（Relative Addressing）： 使用相对于当前指令位置的偏移量，而不是绝对地址。这种方式通常用于实现跳转或条件分支。
5. 索引寻址（Index Addressing）： 类似于基址寻址，但是使用一个索引寄存器的值与指令中的偏移量相加。索引寻址允许更灵活地处理数组或表。
6. 堆栈寻址（Stack Addressing）： 使用堆栈的数据结构，栈指针指示栈的当前位置。通常用于存储临时数据和实现子程序调用。
7. 寄存器寻址（Register Addressing）： 数据直接存储在寄存器中，指令中使用寄存器的编号来访问数据。

这些寻址方式的选择取决于计算机的体系结构和指令集设计。在程序执行时，计算机根据指令中的地址信息，通过总线系统访问存储器中的数据。寻址方式的设计影响了计算机的灵活性、性能和编程的便捷性。不同的计算机体系结构和架构可能采用不同的寻址方式。


## 冯诺依曼瓶颈

- 定义: 由计算机内存结构引起的性能瓶颈
- 原因
  - 存储器瓶颈： 冯·诺依曼架构中，存储器（内存）通常是计算机性能的瓶颈之一。CPU 与内存之间的数据传输速度相对较慢，特别是在大规模数据处理时，CPU 可能需要等待数据的加载或存储操作完成，从而导致性能瓶颈。
  - 带宽瓶颈： 单一总线结构限制了数据在计算机内部的传输带宽。这可能导致在大规模并行操作或对大量数据进行高速处理时，总线成为性能瓶颈。
  - 时钟频率瓶颈： 冯·诺依曼架构下，时钟频率的提升曾是提高计算机性能的主要途径。然而，由于功耗和散热等问题，时钟频率的进一步提高变得困难，这导致了时钟频率瓶颈。
  - 能效瓶颈： 随着计算机应用的多样化和对能效的需求增加，冯·诺依曼架构在能效方面存在一些限制。例如，某些计算任务可能需要定制化的硬件架构以提高能效。
  - 复杂性瓶颈： 冯·诺依曼架构的通用性也带来了复杂性。在一些特定应用场景下，需要更专门化的硬件来提高性能和效率，而通用计算机架构可能显得过于复杂。
  - 安全性瓶颈： 冯·诺依曼架构的设计并没有特别强调安全性。因此，在当前计算环境中，对于一些安全性问题，如恶意软件攻击和数据泄漏，冯·诺依曼架构可能会面临一定的挑战。
- 优化
  - 高速缓存: 减少内存访问次数
  - 多通道内存: 提高内存总带宽
  - 高带宽总线
  - 并行执行多个指令: pipeline, 超标量和乱序执行
  - 异步传输: 允许外设和主内存在不同的时钟域中工作，减少对总线的竞争，提高数据传输效率
  - 新的存储技术: 提升内存读写速度
  - 并行计算和分布式计算

## pipeline 流水线架构
> 流水线架构（Pipeline Architecture）是一种**计算机处理器设计**的方式，通过将指令执行划分为多个阶段，并在每个阶段使用专门的硬件来执行部分任务，以提高指令的执行效率。这种设计方式使得多个指令能够在同一时间在不同阶段同时进行处理，从而提高了整体的吞吐量。

流水线架构通常包括以下几个阶段：

1. 取指（IF - Instruction Fetch）： 从内存中取得下一条指令。
2. 译码（ID - Instruction Decode）： 对指令进行译码，确定执行的操作。
3. 执行（EX - Execution）： 执行指令的操作，可能包括算术运算、逻辑运算等。
4. 访存（MEM - Memory Access）： 如果需要访问内存，则在这个阶段进行读写内存的操作。
5. 写回（WB - Write Back）： 将执行阶段得到的结果写回寄存器文件。

应用场景
1. 通用计算领域： 流水线架构广泛应用于通用计算领域，包括个人计算机、工作站和服务器等。处理器通过流水线架构可以更高效地执行一系列指令，提高整体性能。
2. 嵌入式系统： 流水线架构在嵌入式系统中也得到广泛应用，因为它能够提供高性能和能效的组合。嵌入式系统包括智能手机、平板电脑、物联网设备等。
3. 高性能计算（HPC）： 流水线架构对于高性能计算应用非常重要，因为在科学计算、模拟和数据处理等场景中，处理器需要高吞吐量和高效率，而流水线能够提供这种能力。
4. 图形处理单元（GPU）： 许多现代GPU采用了流水线架构，用于并行处理图形和通用计算任务。流水线能够使得GPU同时处理多个图形或计算任务，提高整体性能。
5. 网络处理器： 在网络设备和通信领域，流水线架构也常被使用，以处理大量的数据包和网络通信任务。
6. 数字信号处理器（DSP）： 流水线架构在DSP领域也很常见，用于处理数字信号、音频和图像等领域的信号处理任务。



## 目前主流计算机架构

> x86_64（64位x86）和ARM架构是当前主流的**计算机架构**。这两种架构在不同领域和设备上广泛应用，涵盖了个人计算机、服务器、移动设备、嵌入式系统等各个领域。


- x86_64（64位x86）架构：
  - 应用领域： 个人计算机、工作站、服务器等。
  - 特点： x86_64架构是x86架构的64位扩展，提供更大的内存地址空间和寄存器位宽，支持更复杂的指令集。主要生产厂商包括Intel和AMD。

- ARM架构：
  - 应用领域： 移动设备（如智能手机、平板电脑）、嵌入式系统、服务器、物联网设备等。
  - 特点： ARM架构设计注重低功耗、高性能的特点，适用于移动设备等对能效要求较高的场景。ARM架构有多个版本，包括ARMv7、ARMv8等，其中ARMv8引入了64位指令集（AArch64），提供更大的地址空间。

### x86 架构

> x86架构是一种基于Intel 8086处理器的指令集架构，它最初由Intel推出，并成为个人计算机领域的主流架构。

以下是关于x86_64架构的一些详细信息：

1. 历史背景： x86架构最早出现于Intel的8086处理器，于1978年推出。随着时间的推移，x86架构逐渐演进，包括80286、80386、80486等多个版本，其中80386是首个支持32位操作的处理器。
2. 指令集架构： x86指令集是一种复杂的CISC（复杂指令集计算机）指令集，包含大量的指令和寄存器。x86指令集在历史上逐步扩展，包括对浮点运算、SIMD指令、多核心处理等方面的增强。
3. 寄存器： x86架构包括通用寄存器、段寄存器、标志寄存器等。通用寄存器的位宽逐步扩展，最初是16位，后来发展到32位和64位。x86_64架构引入了一组新的64位通用寄存器。
4. 地址空间： x86架构的物理内存寻址能力取决于具体的版本，但在32位模式下通常是4GB。在64位模式下，x86_64提供了更大的虚拟地址空间，可以支持极大的物理内存容量。
5. 操作模式： x86架构支持多种操作模式，其中实模式、保护模式和长模式是最为重要的。长模式是x86_64架构引入的64位模式，允许操作系统和应用程序充分利用64位寄存器和指令。
6. 系统调用和调用约定： x86架构使用一定的系统调用号和调用约定，操作系统通过这些系统调用提供服务。调用约定规定了函数参数传递、栈的使用方式等规则。
7. 主要生产商： 主要生产x86架构处理器的公司包括Intel和AMD。它们推出的处理器被广泛应用于个人计算机、服务器、工作站等领域。
8. 应用领域： x86架构最初用于个人计算机，但随着时间的推移，它逐渐扩展到服务器、工作站、嵌入式系统等各种领域。几乎所有主流的操作系统，包括Windows、Linux、macOS等，都支持x86架构。

### ARM架构

> ARM架构是一种基于RISC（精简指令集计算机）设计思想的指令集架构，由ARM Holdings公司开发。ARM架构的设计注重低功耗、高性能、成本效益和可伸缩性，使其在移动设备、嵌入式系统和其他领域得到广泛应用。

以下是关于ARM架构的一些基本信息:

1. 设计思想： ARM（Acorn RISC Machine）架构采用RISC设计思想，即通过精简指令集、提高执行效率和降低功耗来提高性能。ARM的设计目标是在功耗有限的情况下实现高性能。
2. 指令集架构： ARM指令集被设计为简单、高效，并且具有可伸缩性。最初是32位的，后来推出了64位的版本（ARMv8-A），为更大的内存和更复杂的计算任务提供了支持。
3. 寄存器： ARM架构的寄存器集包括通用寄存器、程序计数器、状态寄存器等。通用寄存器的数量通常较少，这是为了降低指令的复杂度和提高执行效率。
4. 地址空间： ARM架构提供了较大的虚拟地址空间，具体取决于版本。在32位模式下，通常支持4GB的虚拟地址空间，而64位版本则支持更大的地址空间。
5. 操作模式： ARM架构支持不同的操作模式，包括用户模式、系统模式、中断模式等。这些模式允许CPU在不同的执行环境下工作，提供了更好的安全性和隔离性。
6. 应用领域： ARM架构最初广泛应用于移动设备，如智能手机和平板电脑。随着技术的发展，ARM架构也被广泛应用于嵌入式系统、物联网设备、网络设备、家电和汽车等领域。
7. 主要生产商： ARM架构的许可模式允许其他公司许可ARM的设计，并根据需要进行定制。ARM Holdings公司本身不生产芯片，而是通过合作伙伴的许可来推动ARM架构的广泛应用。主要的ARM架构芯片制造商包括英特尔、高通、苹果、三星、华为等。
8. 生态系统： ARM架构建立了庞大的生态系统，包括丰富的软件和工具支持。这使得开发人员能够更容易地在ARM架构上进行软件开发，从而推动了ARM在不同领域的广泛应用。

